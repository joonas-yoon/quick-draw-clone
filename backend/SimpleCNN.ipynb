{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting quickdraw\n",
      "  Downloading quickdraw-1.0.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: pillow in /Users/joonas/Works/repos/QuickDraw/.venv/lib/python3.10/site-packages (from quickdraw) (9.5.0)\n",
      "Requirement already satisfied: requests in /Users/joonas/Works/repos/QuickDraw/.venv/lib/python3.10/site-packages (from quickdraw) (2.30.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/joonas/Works/repos/QuickDraw/.venv/lib/python3.10/site-packages (from requests->quickdraw) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/joonas/Works/repos/QuickDraw/.venv/lib/python3.10/site-packages (from requests->quickdraw) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/joonas/Works/repos/QuickDraw/.venv/lib/python3.10/site-packages (from requests->quickdraw) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/joonas/Works/repos/QuickDraw/.venv/lib/python3.10/site-packages (from requests->quickdraw) (2023.5.7)\n",
      "Downloading quickdraw-1.0.0-py3-none-any.whl (11 kB)\n",
      "Installing collected packages: quickdraw\n",
      "Successfully installed quickdraw-1.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install quickdraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchmetrics import Accuracy\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import patches, path, pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import quickdraw as QD\n",
    "\n",
    "CLASSES = [\n",
    "    \"aircraft carrier\",\n",
    "    \"airplane\",\n",
    "    \"alarm clock\",\n",
    "    \"ambulance\",\n",
    "    \"angel\",\n",
    "    \"animal migration\",\n",
    "    \"ant\",\n",
    "    \"anvil\",\n",
    "    \"apple\",\n",
    "    \"arm\",\n",
    "    \"asparagus\",\n",
    "    \"axe\",\n",
    "    \"backpack\",\n",
    "    \"banana\",\n",
    "    \"bandage\",\n",
    "    \"barn\",\n",
    "    \"baseball\",\n",
    "    \"baseball bat\",\n",
    "    \"basket\",\n",
    "    \"basketball\",\n",
    "    \"bat\",\n",
    "    \"bathtub\",\n",
    "    \"beach\",\n",
    "    \"bear\",\n",
    "    \"beard\",\n",
    "    \"bed\",\n",
    "    \"bee\",\n",
    "    \"belt\",\n",
    "    \"bench\",\n",
    "    \"bicycle\",\n",
    "    \"binoculars\",\n",
    "    \"bird\",\n",
    "    \"birthday cake\",\n",
    "    \"blackberry\",\n",
    "    \"blueberry\",\n",
    "    \"book\",\n",
    "    \"boomerang\",\n",
    "    \"bottlecap\",\n",
    "    \"bowtie\",\n",
    "    \"bracelet\",\n",
    "    \"brain\",\n",
    "    \"bread\",\n",
    "    \"bridge\",\n",
    "    \"broccoli\",\n",
    "    \"broom\",\n",
    "    \"bucket\",\n",
    "    \"bulldozer\",\n",
    "    \"bus\",\n",
    "    \"bush\",\n",
    "    \"butterfly\",\n",
    "    \"cactus\",\n",
    "    \"cake\",\n",
    "    \"calculator\",\n",
    "    \"calendar\",\n",
    "    \"camel\",\n",
    "    \"camera\",\n",
    "    \"camouflage\",\n",
    "    \"campfire\",\n",
    "    \"candle\",\n",
    "    \"cannon\",\n",
    "    \"canoe\",\n",
    "    \"car\",\n",
    "    \"carrot\",\n",
    "    \"castle\",\n",
    "    \"cat\",\n",
    "    \"ceiling fan\",\n",
    "    \"cello\",\n",
    "    \"cell phone\",\n",
    "    \"chair\",\n",
    "    \"chandelier\",\n",
    "    \"church\",\n",
    "    \"circle\",\n",
    "    \"clarinet\",\n",
    "    \"clock\",\n",
    "    \"cloud\",\n",
    "    \"coffee cup\",\n",
    "    \"compass\",\n",
    "    \"computer\",\n",
    "    \"cookie\",\n",
    "    \"cooler\",\n",
    "    \"couch\",\n",
    "    \"cow\",\n",
    "    \"crab\",\n",
    "    \"crayon\",\n",
    "    \"crocodile\",\n",
    "    \"crown\",\n",
    "    \"cruise ship\",\n",
    "    \"cup\",\n",
    "    \"diamond\",\n",
    "    \"dishwasher\",\n",
    "    \"diving board\",\n",
    "    \"dog\",\n",
    "    \"dolphin\",\n",
    "    \"donut\",\n",
    "    \"door\",\n",
    "    \"dragon\",\n",
    "    \"dresser\",\n",
    "    \"drill\",\n",
    "    \"drums\",\n",
    "    \"duck\",\n",
    "    \"dumbbell\",\n",
    "    \"ear\",\n",
    "    \"elbow\",\n",
    "    \"elephant\",\n",
    "    \"envelope\",\n",
    "    \"eraser\",\n",
    "    \"eye\",\n",
    "    \"eyeglasses\",\n",
    "    \"face\",\n",
    "    \"fan\",\n",
    "    \"feather\",\n",
    "    \"fence\",\n",
    "    \"finger\",\n",
    "    \"fire hydrant\",\n",
    "    \"fireplace\",\n",
    "    \"firetruck\",\n",
    "    \"fish\",\n",
    "    \"flamingo\",\n",
    "    \"flashlight\",\n",
    "    \"flip flops\",\n",
    "    \"floor lamp\",\n",
    "    \"flower\",\n",
    "    \"flying saucer\",\n",
    "    \"foot\",\n",
    "    \"fork\",\n",
    "    \"frog\",\n",
    "    \"frying pan\",\n",
    "    \"garden\",\n",
    "    \"garden hose\",\n",
    "    \"giraffe\",\n",
    "    \"goatee\",\n",
    "    \"golf club\",\n",
    "    \"grapes\",\n",
    "    \"grass\",\n",
    "    \"guitar\",\n",
    "    \"hamburger\",\n",
    "    \"hammer\",\n",
    "    \"hand\",\n",
    "    \"harp\",\n",
    "    \"hat\",\n",
    "    \"headphones\",\n",
    "    \"hedgehog\",\n",
    "    \"helicopter\",\n",
    "    \"helmet\",\n",
    "    \"hexagon\",\n",
    "    \"hockey puck\",\n",
    "    \"hockey stick\",\n",
    "    \"horse\",\n",
    "    \"hospital\",\n",
    "    \"hot air balloon\",\n",
    "    \"hot dog\",\n",
    "    \"hot tub\",\n",
    "    \"hourglass\",\n",
    "    \"house\",\n",
    "    \"house plant\",\n",
    "    \"hurricane\",\n",
    "    \"ice cream\",\n",
    "    \"jacket\",\n",
    "    \"jail\",\n",
    "    \"kangaroo\",\n",
    "    \"key\",\n",
    "    \"keyboard\",\n",
    "    \"knee\",\n",
    "    \"knife\",\n",
    "    \"ladder\",\n",
    "    \"lantern\",\n",
    "    \"laptop\",\n",
    "    \"leaf\",\n",
    "    \"leg\",\n",
    "    \"light bulb\",\n",
    "    \"lighter\",\n",
    "    \"lighthouse\",\n",
    "    \"lightning\",\n",
    "    \"line\",\n",
    "    \"lion\",\n",
    "    \"lipstick\",\n",
    "    \"lobster\",\n",
    "    \"lollipop\",\n",
    "    \"mailbox\",\n",
    "    \"map\",\n",
    "    \"marker\",\n",
    "    \"matches\",\n",
    "    \"megaphone\",\n",
    "    \"mermaid\",\n",
    "    \"microphone\",\n",
    "    \"microwave\",\n",
    "    \"monkey\",\n",
    "    \"moon\",\n",
    "    \"mosquito\",\n",
    "    \"motorbike\",\n",
    "    \"mountain\",\n",
    "    \"mouse\",\n",
    "    \"moustache\",\n",
    "    \"mouth\",\n",
    "    \"mug\",\n",
    "    \"mushroom\",\n",
    "    \"nail\",\n",
    "    \"necklace\",\n",
    "    \"nose\",\n",
    "    \"ocean\",\n",
    "    \"octagon\",\n",
    "    \"octopus\",\n",
    "    \"onion\",\n",
    "    \"oven\",\n",
    "    \"owl\",\n",
    "    \"paintbrush\",\n",
    "    \"paint can\",\n",
    "    \"palm tree\",\n",
    "    \"panda\",\n",
    "    \"pants\",\n",
    "    \"paper clip\",\n",
    "    \"parachute\",\n",
    "    \"parrot\",\n",
    "    \"passport\",\n",
    "    \"peanut\",\n",
    "    \"pear\",\n",
    "    \"peas\",\n",
    "    \"pencil\",\n",
    "    \"penguin\",\n",
    "    \"piano\",\n",
    "    \"pickup truck\",\n",
    "    \"picture frame\",\n",
    "    \"pig\",\n",
    "    \"pillow\",\n",
    "    \"pineapple\",\n",
    "    \"pizza\",\n",
    "    \"pliers\",\n",
    "    \"police car\",\n",
    "    \"pond\",\n",
    "    \"pool\",\n",
    "    \"popsicle\",\n",
    "    \"postcard\",\n",
    "    \"potato\",\n",
    "    \"power outlet\",\n",
    "    \"purse\",\n",
    "    \"rabbit\",\n",
    "    \"raccoon\",\n",
    "    \"radio\",\n",
    "    \"rain\",\n",
    "    \"rainbow\",\n",
    "    \"rake\",\n",
    "    \"remote control\",\n",
    "    \"rhinoceros\",\n",
    "    \"rifle\",\n",
    "    \"river\",\n",
    "    \"roller coaster\",\n",
    "    \"rollerskates\",\n",
    "    \"sailboat\",\n",
    "    \"sandwich\",\n",
    "    \"saw\",\n",
    "    \"saxophone\",\n",
    "    \"school bus\",\n",
    "    \"scissors\",\n",
    "    \"scorpion\",\n",
    "    \"screwdriver\",\n",
    "    \"sea turtle\",\n",
    "    \"see saw\",\n",
    "    \"shark\",\n",
    "    \"sheep\",\n",
    "    \"shoe\",\n",
    "    \"shorts\",\n",
    "    \"shovel\",\n",
    "    \"sink\",\n",
    "    \"skateboard\",\n",
    "    \"skull\",\n",
    "    \"skyscraper\",\n",
    "    \"sleeping bag\",\n",
    "    \"smiley face\",\n",
    "    \"snail\",\n",
    "    \"snake\",\n",
    "    \"snorkel\",\n",
    "    \"snowflake\",\n",
    "    \"snowman\",\n",
    "    \"soccer ball\",\n",
    "    \"sock\",\n",
    "    \"speedboat\",\n",
    "    \"spider\",\n",
    "    \"spoon\",\n",
    "    \"spreadsheet\",\n",
    "    \"square\",\n",
    "    \"squiggle\",\n",
    "    \"squirrel\",\n",
    "    \"stairs\",\n",
    "    \"star\",\n",
    "    \"steak\",\n",
    "    \"stereo\",\n",
    "    \"stethoscope\",\n",
    "    \"stitches\",\n",
    "    \"stop sign\",\n",
    "    \"stove\",\n",
    "    \"strawberry\",\n",
    "    \"streetlight\",\n",
    "    \"string bean\",\n",
    "    \"submarine\",\n",
    "    \"suitcase\",\n",
    "    \"sun\",\n",
    "    \"swan\",\n",
    "    \"sweater\",\n",
    "    \"swing set\",\n",
    "    \"sword\",\n",
    "    \"syringe\",\n",
    "    \"table\",\n",
    "    \"teapot\",\n",
    "    \"teddy-bear\",\n",
    "    \"telephone\",\n",
    "    \"television\",\n",
    "    \"tennis racquet\",\n",
    "    \"tent\",\n",
    "    \"The Eiffel Tower\",\n",
    "    \"The Great Wall of China\",\n",
    "    \"The Mona Lisa\",\n",
    "    \"tiger\",\n",
    "    \"toaster\",\n",
    "    \"toe\",\n",
    "    \"toilet\",\n",
    "    \"tooth\",\n",
    "    \"toothbrush\",\n",
    "    \"toothpaste\",\n",
    "    \"tornado\",\n",
    "    \"tractor\",\n",
    "    \"traffic light\",\n",
    "    \"train\",\n",
    "    \"tree\",\n",
    "    \"triangle\",\n",
    "    \"trombone\",\n",
    "    \"truck\",\n",
    "    \"trumpet\",\n",
    "    \"t-shirt\",\n",
    "    \"umbrella\",\n",
    "    \"underwear\",\n",
    "    \"van\",\n",
    "    \"vase\",\n",
    "    \"violin\",\n",
    "    \"washing machine\",\n",
    "    \"watermelon\",\n",
    "    \"waterslide\",\n",
    "    \"whale\",\n",
    "    \"wheel\",\n",
    "    \"windmill\",\n",
    "    \"wine bottle\",\n",
    "    \"wine glass\",\n",
    "    \"wristwatch\",\n",
    "    \"yoga\",\n",
    "    \"zebra\",\n",
    "    \"zigzag\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading aircraft carrier drawings\n",
      "load complete\n"
     ]
    }
   ],
   "source": [
    "datagroup = QD.QuickDrawDataGroup(CLASSES[0], max_drawings=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "class QuickDrawDataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, name, max_drawings, transform, recognized=True, classes=CLASSES):\n",
    "        self.id = classes.index(name)\n",
    "        self.datagroup = QD.QuickDrawDataGroup(name,\n",
    "                                               max_drawings=max_drawings, \n",
    "                                               recognized=recognized)\n",
    "        self.max_drawings = max_drawings\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.datagroup.drawing_count\n",
    "    \n",
    "    def _get_single_item(self, index: int):\n",
    "        img = self.datagroup.get_drawing(index).image\n",
    "        return (self.transform(img), self.id)\n",
    "\n",
    "    def __getitem__(self, index: Union[int, slice, np.ndarray]):\n",
    "        if type(index) == slice or type(index) == np.ndarray:\n",
    "            if type(index) == slice:\n",
    "                index = range(index.start, index.stop, index.step or 1)\n",
    "            return [self._get_single_item(i) for i in index]\n",
    "        return self._get_single_item(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading aircraft carrier drawings\n",
      "load complete\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "ds = QuickDrawDataSet(CLASSES[0], max_drawings=10000, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(<PIL.Image.Image image mode=RGB size=255x255>, 0),\n",
       " (<PIL.Image.Image image mode=RGB size=255x255>, 0),\n",
       " (<PIL.Image.Image image mode=RGB size=255x255>, 0),\n",
       " (<PIL.Image.Image image mode=RGB size=255x255>, 0)]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[np.array([1, 3, 5, 7])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bisect\n",
    "\n",
    "class QuickDrawDataAllSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, classes, max_drawings, transform, recognized=True):\n",
    "        params = dict(\n",
    "            max_drawings=max_drawings, transform=transform, classes=classes, recognized=recognized\n",
    "        )\n",
    "        self.groups = [QuickDrawDataSet(cls, **params) for cls in classes]\n",
    "        self.offset = [0]\n",
    "        self.count = 0\n",
    "        for g in self.groups:\n",
    "            self.count += len(g)\n",
    "            self.offset.append(self.count)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.count\n",
    "    \n",
    "    def get_single_item(self, index: int):\n",
    "        gi = bisect.bisect_right(self.offset, index) - 1\n",
    "        return self.groups[gi][index - self.offset[gi]]\n",
    "\n",
    "    def __getitem__(self, index: Union[int, slice, np.ndarray]):\n",
    "        if type(index) == slice or type(index) == np.ndarray:\n",
    "            if type(index) == slice:\n",
    "                index = range(index.start, index.stop, index.step or 1)\n",
    "            return [self.get_single_item(i) for i in index]\n",
    "        return self.get_single_item(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading aircraft carrier drawings\n",
      "load complete\n",
      "loading airplane drawings\n",
      "load complete\n",
      "loading alarm clock drawings\n",
      "load complete\n",
      "loading ambulance drawings\n",
      "load complete\n",
      "loading angel drawings\n",
      "load complete\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.QuickDrawDataAllSet at 0x29f9f8a30>"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def transfom(data):\n",
    "    print(data)\n",
    "    return transforms.ToTensor()(data)\n",
    "\n",
    "dataset_all = QuickDrawDataAllSet(CLASSES[:5], max_drawings=1000, transform=transforms.ToTensor())\n",
    "dataset_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          ...,\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.]],\n",
       " \n",
       "         [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          ...,\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.]],\n",
       " \n",
       "         [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          ...,\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.]]]),\n",
       " 0)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_all[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([[[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           ...,\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.]],\n",
       "  \n",
       "          [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           ...,\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.]],\n",
       "  \n",
       "          [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           ...,\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.]]]),\n",
       "  0),\n",
       " (tensor([[[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           ...,\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.]],\n",
       "  \n",
       "          [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           ...,\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.]],\n",
       "  \n",
       "          [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           ...,\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.]]]),\n",
       "  0),\n",
       " (tensor([[[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           ...,\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.]],\n",
       "  \n",
       "          [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           ...,\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.]],\n",
       "  \n",
       "          [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           ...,\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.]]]),\n",
       "  0)]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_all[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_index(indices, train_size: float) -> tuple:\n",
    "    n = len(indices)\n",
    "    i = int(n * train_size)\n",
    "    return (indices[:i], indices[i:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, SequentialSampler, SubsetRandomSampler\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "index_all = np.arange(len(dataset_all))\n",
    "train_valid_idx, test_idx = split_index(index_all, train_size=0.8)\n",
    "train_idx, valid_idx = split_index(train_valid_idx, train_size=0.7)\n",
    "\n",
    "train_subsampler = SubsetRandomSampler(train_idx)\n",
    "valid_subsampler = SequentialSampler(valid_idx)\n",
    "test_subsampler = SequentialSampler(test_idx)\n",
    "\n",
    "train_dataloader = DataLoader(dataset_all, batch_size=BATCH_SIZE, sampler=train_subsampler)\n",
    "valid_dataloader = DataLoader(dataset_all, batch_size=BATCH_SIZE, sampler=valid_subsampler)\n",
    "test_dataloader = DataLoader(dataset_all, batch_size=BATCH_SIZE, sampler=test_subsampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batch, label_batch = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 3, 255, 255])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([256]),\n",
       " tensor([1, 1, 2, 1, 1, 1, 1, 2, 2, 0, 0, 2, 0, 2, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0,\n",
       "         1, 1, 1, 2, 1, 1, 2, 1, 1, 0, 1, 0, 2, 1, 0, 1, 1, 0, 1, 2, 2, 2, 0, 1,\n",
       "         2, 2, 2, 1, 1, 0, 2, 0, 1, 1, 0, 0, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 2, 1,\n",
       "         1, 2, 0, 2, 1, 1, 2, 0, 1, 0, 1, 0, 2, 1, 2, 0, 2, 2, 0, 2, 1, 1, 1, 2,\n",
       "         1, 0, 0, 2, 1, 0, 2, 0, 1, 0, 0, 0, 1, 2, 0, 2, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "         1, 0, 1, 2, 1, 1, 0, 0, 0, 0, 2, 0, 2, 0, 1, 2, 1, 1, 1, 2, 2, 1, 1, 1,\n",
       "         2, 1, 0, 0, 0, 2, 1, 1, 1, 0, 1, 0, 1, 0, 1, 2, 1, 1, 1, 2, 2, 2, 0, 2,\n",
       "         1, 0, 0, 2, 1, 1, 1, 1, 0, 1, 2, 1, 2, 1, 0, 1, 0, 1, 0, 1, 0, 1, 2, 1,\n",
       "         2, 0, 0, 1, 2, 0, 0, 1, 0, 1, 2, 0, 0, 1, 0, 2, 1, 0, 2, 1, 1, 1, 2, 2,\n",
       "         0, 0, 0, 1, 2, 1, 0, 0, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 0, 1, 2, 1, 2,\n",
       "         0, 1, 0, 0, 2, 1, 0, 1, 0, 1, 2, 1, 1, 2, 0, 1]))"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_batch.shape, label_batch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
